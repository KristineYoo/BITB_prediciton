{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea7bcb-66a0-47d5-b01e-267a2a46ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installs packages, sets up the environment\n",
    "#you only need to run this once \n",
    "#a notebook cell with ! allows you to run a terminal/command-line command\n",
    "%pip install yfinance pandas numpy scikit-learn matplotlib seaborn\n",
    "#yfinance --> Gets stock prices by dowloading OHLCV from Yahoo's finance API\n",
    "#pandas --> data manipulation library in Python \n",
    "#       --> joining datasets \n",
    "#       --> filtering rows/columns\n",
    "#       --> computing rolling windows like moving averages and volatility\n",
    "#       --> date/time indexing\n",
    "#numpy --> numerical computing like arrays, vectorized math, fast calculations, log returns, matrix operations\n",
    "#scikit-learn --> ml python library. Has premade models for Linear regression, Lasso(?) Training, test splitting(?), scalers(?), model evaluation metrics\n",
    "#matplotlib --> library for creating plots and visualizations \n",
    "#seaborn --> built on top of matplotlib but makes prettier statistical plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b413f1-9523-447c-81fc-826f7c3e6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "#LinearRegression --> creats a simple linear model y = a +bX for predictin continuous numbers\n",
    "#Ridge --> Same as LinearRegression but includes a penalty to prevent overfitting (useful for noisy data, correlated features, too many features)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#StadardScaler --> standardized your features so they have mean = 0, and Standard Deviation = 1\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "#mean_squared_error(MSE) --> measures average squared difference between predictied and true values\n",
    "#mean_absolute_error --> measufres average absolute difference, treats all errors equally\n",
    "#r2_score --> measures how well your model explains the variance in the data (?)\n",
    "#         --> ranges from negative infinity to 1, higher is better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01aeaa7-1c73-45cd-992e-1fb291fae0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download BITB data \n",
    "\n",
    "ticker = \"BITB\"\n",
    "#stores the ETF's ticker symbol as a variable\n",
    "\n",
    "df = yf.Ticker(ticker).history(period=\"max\")\n",
    "#yf.Ticker(ticker) --> creates a ticker object for BITB (yf = yfinance)\n",
    "#history(period=\"max\") --> downloads historical price data for as long as this ETF has existed\n",
    "#this will return a panda Dataframe with all the data columns \n",
    "\n",
    "df = df[['Open','High','Low','Close','Volume']].copy()\n",
    "#this changes the returned value of df (the panda dataframe) to be a dataframe with only the columns we care abour \n",
    "#the .copy() avoids warning messages by making a clean copy\n",
    "\n",
    "df.head() \n",
    "#this will show the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d61da-33d2-4754-bfe3-fcf38c7ec131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute daily returns\n",
    "\n",
    "df['return'] = df['Close'].pct_change() \n",
    "#this will create a new column in the dataframe called 'return'\n",
    "#'return' will contain the day-to-day percentage change in the close price \n",
    "#return = (close_x - close_(x-1)) / (close x-1) \n",
    "#       = (close_x / close_(x-1)) -1 \n",
    "#the values returned will be fractions (to have it formated as a percentage multiply by 100)\n",
    "#the very first row will be NaN because there's no previous day to compare to\n",
    "\n",
    "df = df.dropna()\n",
    "#this will remove all rows that contain NaN in any column (like the first row)\n",
    "#this is because machines learniing models and many operations expect no missing values\n",
    "#NaN may appear in this project due to missing prices, holidays, etc.\n",
    "\n",
    "df['return'].describe()\n",
    "#this will produce summary statistics for the return column \n",
    "#    --> count(num of non-NaN observations), max/min(worst and best one day returns), std(volatility), 25%/50%/75%(meadian and quartiles), mean (average daily return), name, and dtype \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26839285-4a5f-4f9c-826f-def985450e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering (process of creating, modifying, or selecting input variables in a dataset)\n",
    "#this cell will create lagged returns(?), moving averages(?), volatility, and volume ratio\n",
    "\n",
    "#lagging returns\n",
    "\n",
    "df['r_lag1'] = df['return'].shift(1)\n",
    "#this will create a new column called \"r_lag1\"\n",
    "#we do this because in time series (like stock prices) you want to predict today's returns using past data \n",
    "#shift(1) will move everything down by 1 so each rown now contains the previous day's returns \n",
    "\n",
    "# moving averages of returns (shifted so they are only info from the past)\n",
    "df['ma5'] = df['return'].rolling(window=5).mean().shift(1)\n",
    "df['ma10'] = df['return'].rolling(window=10).mean().shift(1)\n",
    "#rolling(window=5).mean() --> calculate the average return over the past 5 days \n",
    "#shift(1) --> move it down so we only use past data \n",
    "\n",
    "# volatility (rolling std)\n",
    "df['vol5'] = df['return'].rolling(window=5).std().shift(1)\n",
    "df['vol10'] = df['return'].rolling(window=10).std().shift(1)\n",
    "#this calculates how much returns fluctaute over the past days. This is a measure of volatility \n",
    "#volatility is the degree of variation in the price of an asset or market over time, indicating how quickly and unpredictably its value can change\n",
    "\n",
    "# volume relative to 10-day average\n",
    "df['vol_avg10'] = df['Volume'].rolling(window=10).mean().shift(1)\n",
    "#takes the average trading colyne over the past 10 days \n",
    "df['vol_ratio'] = df['Volume'] / df['vol_avg10']\n",
    "#todays volume divided by the past 10 day average \n",
    "#vol_ratio > 1, higher than average trading activity \n",
    "#vol_ratio < 1, lower than average trading activity\n",
    "#this will help indicate trends, news, or unusual market behavior\n",
    "\n",
    "# Drop rows with NaNs produced by shifting/rolling\n",
    "df = df.dropna()\n",
    "df.tail()\n",
    "#returns the last couple rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6be11-8b9a-4b5d-bc08-4379d2d93aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Split (time series) \n",
    "#in machine learning, we usually split our data into two sets \n",
    "#              - traning set: used to train the model \n",
    "#              - test set: used to evaluate the model \n",
    "#in time series data, there is a time order (past-> present-> future)\n",
    "#we can't randomly shuffle data because that might make future data leake into the \n",
    "\n",
    "train_size = int(len(df) * 0.8)\n",
    "#len(df)--> counts the number of rows in the DataFrame \n",
    "#* .8 will take 80 percent of the rows. That is a common choice for the training set for some reason \n",
    "#int() will make sure the result is an integer \n",
    "\n",
    "train_df = df.iloc[:train_size]\n",
    "#selects rows from the start up to (not inlcuding) the index 'train_size'\n",
    "#this will become the training dataset\n",
    "#iloc is integer location based indexing, so it slices rows by position, not by label \n",
    "#               - iloc stands for integer location \n",
    "#               - it lets you selecr rows and columns by their ineteger position, not by their labels\n",
    "#               - basic syntax --> df.iloc[row_selection, column_selection]\n",
    "\n",
    "test_df = df.iloc[train_size:]\n",
    "#this selects rows from train_size to the end\n",
    "#this becomes the test dataset f\n",
    "\n",
    "#test_df is the end of the dataset while train_size is the beginning 80% because this is a time series dataset \n",
    "#|----------Training----------|----Test----|\n",
    "#this would mimic how you would make predictions in real life:train in the past, test on the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b12ad-9151-4e74-a62e-32dc365469cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Feautures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#importing the scaler, StandardScaler is used to standardize features\n",
    "#Transforms the data so each feature has Mean = 0 & StanDev = 1\n",
    "\n",
    "features = [\"r_lag1\", \"ma5\", \"vol10\", \"vol_ratio\"]\n",
    "#input variables for the input variables for the models \n",
    "#   r_lag1 -> prevous return\n",
    "#   ma5 ->\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(train_df[features])\n",
    "X_test = scaler.transform(test_df[features])\n",
    "\n",
    "y_train = train_df[\"return\"].values\n",
    "y_test = test_df[\"return\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0696628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the Linear Regression Model\n",
    "\n",
    "#OLS (Ordinary Least Squares) - What straight line fits my data best\n",
    "#Teaching a model how to predict returns using past data \n",
    "model = LinearRegression() \n",
    "#LinearRegression() can't predict anything yet, needs to learn first \n",
    "model.fit(X_train, y_train) #where learning happens \n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d736ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction and Evaluation \n",
    "#Checks how good predictions are \n",
    "y_pred = model.predict(X_test)\n",
    "#model.predict(...) uses a learned rule from training \n",
    "#X_test is data the model has never seen before \n",
    "#y_pred are the predicted returns in list/array format \n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "#mse is how wrong the predictions are sqaured\n",
    "#This is done by... \n",
    "#   taking actual - predicted \n",
    "#   squaring it \n",
    "#   taking the average over all days \n",
    "#Lower = better \n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "#mae is the average size of error \n",
    "#This is done by... \n",
    "#   taking |actual - predicted|\n",
    "#   taking the average of this \n",
    "\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "#how much of the variation in returns is explained by model \n",
    "\n",
    "\n",
    "dir_acc = (np.sign(y_pred) == np.sign(y_test)).mean()\n",
    "#directional accuracy \n",
    "#np.sign(y_pred)-> converts predictions from (+1, -1, 0) to (positive, negative, or zero)\n",
    "#ensures directions of returns of predicted data and real data are equal \n",
    "\n",
    "#print results\n",
    "print(f\"MSE: {mse:.6e}\") #penalizes big erros \n",
    "print(f\"MAE: {mae:.6e}\") #typical prediction error\n",
    "print(f\"R^2: {r2:.4f}\") # how much signal captured \n",
    "print(f\"Directional accuracy: {dir_acc:.3f}\") #trading relavance \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter predicted vs actual\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred, s=8)\n",
    "plt.xlabel(\"Actual return\"); plt.ylabel(\"Predicted return\")\n",
    "plt.title(\"Predicted vs Actual\")\n",
    "plt.plot([-0.2,0.2],[-0.2,0.2], color='red', linewidth=1)  # identity line\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
